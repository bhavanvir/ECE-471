{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0nrIg51CXFF"
      },
      "source": [
        "![UVic logo](https://res-2.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_256,w_256,f_auto,q_auto:eco/v1406151713/wptak6xuezyh36b1hbty.png)\n",
        "\n",
        "# **ECE 471/536 Spring 2023: Computer Vision**\n",
        "## Assignment 1: Math Preliminaries and Programming Introduction\n",
        "### Due date: Febuary 3rd 2023\n",
        "\n",
        "\n",
        "> Student: First Last, V00000000\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srHd9KhbFHcU"
      },
      "source": [
        "## **1. Instructions:** follow the intructions provided on a sequential manner. \n",
        "### 1.0 **Identification** \n",
        "Please enter your name and V number on the text code above.\n",
        "\n",
        "### 1.1 **Submission package**\n",
        "Your final submission package must be submitted using the [BrightSpace](https://https://bright.uvic.ca/d2l/home)  platform. You will find this assignment's specific page under **Course Tools > Assignments**. Your submission package consists of a *.zip* file containing:\n",
        "\n",
        "1.   *.ipynb* file: your modified version of this Google Colab template. Place your complete assignment solution/information in this version.  \n",
        "2.   *.pdf* file: a document containing a writeup with the answers to mathematical questions. \n",
        "\n",
        "### 1.2 **Coding considerations**\n",
        "* In previous years we asked students to complete assignments offline by installing either MATLAB or a Python environment in their computers. In order to standardize the submissions and guarantee that everyone has access to the same Python environment, all assignments are going to be described (by us) and completed (by you) using the same Google Colab reference template script.\n",
        "* Google Colab offers a Python environment that can be accessed in your browser and executed using Google Cloud, so no local installation is necessary. It makes the setting-up process significantly easier! Please read [this quick tutorial](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb) notebook on Google Colab/Python.\n",
        "\n",
        "### 1.3 **Creating your Google Colab submission file**\n",
        "\n",
        "* Modify this template with your solutions to the assignment. You will find \"**TO-DO**\" indicators throughout the assingment highlighting portions of the code you are asked to complete. \n",
        "* Only edit the provided templates in the bounds of the START TODO and END TODO flags.\n",
        "* Colab notebooks are divided into individual cells. You can execute the code inside of a given cell by pressing **CTRL+ENTER**, or that of all cells by pressing **CTRL+F9**. Variables must be \"executed\" in a cell before being used by subsequent ones (the same goes for libraries imported). Note that some cells of this assignment contain flags that must by changed (and executed) before you move forward.\n",
        "* If you completed the whole assignment, make sure that simply pressing \"**CTRL+F9**\" executes all cells correctly. **This is going to be the first marking step we will execute when evaluating your submission**.  \n",
        "\n",
        "### 1.4 **Use of open source code**\n",
        "\n",
        "* The use of small segments of freely-available code is permitted. However, it is **extremely important** that you indicate in your in-code comments where these are used, as well as their sources. Failure to do so can be considered plagiarism, which is a serious offence. Learn more about detection mechanisms and consequences of plagiarism at UVic [here](https://www.uvic.ca/library/research/citation/plagiarism/). Note that the programming assignments are designed so that most of their content should be created by you.     \n",
        "* You can never include too many of these only too few. \n",
        "* A number of functions/algorithms are already implemented by libraries we will use (e.g., [OpenCV](https://opencv.org/), [scikit-learn](https://scikit-learn.org/stable/)), however you should not use them unless otherwise instructed to do so. Mannualy coding some of these function is an important part of the learning process.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQS1k9BUa_8Z"
      },
      "source": [
        "# ~~~~~~~START TODO~~~~~~~~~\n",
        "READ_THE_INSTRUCTIONS_FLAG = True\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab-6ULjWQ4o1"
      },
      "source": [
        "## **2. Mathematical and Theoretical Questions  (20 points)**\n",
        "\n",
        "#### Answer all these questions in a seperate pdf!\n",
        "\n",
        "### **2.1 Linear Algebra**\n",
        "\n",
        "Consider the following vectors and matrix to answer the questions. **If you believe that a particular question has no answer, justify why**. Your work should be reported in the *.pdf* document included in the submission package. \n",
        "\n",
        "$v$ = \\begin{bmatrix} \n",
        "    -1 & 3 & 2\n",
        "    \\end{bmatrix}\n",
        "\n",
        "$B$ = \\begin{bmatrix} \n",
        "    2 & 1 & 0 \\\\\n",
        "    2 & 8 & 0 \\\\\n",
        "    6 & 5 & 0 \n",
        "    \\end{bmatrix}\n",
        "\n",
        "$A$ = \\begin{bmatrix}\n",
        "    1 & 2 & 3 \\\\\n",
        "    -1 & 0 & 1 \\\\\n",
        "    5 & 0 & -1 \n",
        "    \\end{bmatrix}   \n",
        "\n",
        "* 2.1.a) $v + 1$ (1 point) \n",
        "* 2.1.b) $v + v^{T}$ (1 point) \n",
        "* 2.1.c) $v \\cdot v^T$ (dot product) (2 points)\n",
        "* 2.1.d) $v \\times B$ (cross product). Consider that each column in $B$ represents an individual vector. You can follow that same consideration when writing your answer (i.e., as a matrix) (4 points)\n",
        "* 2.1.e) $v \\bullet B$ (matrix multiplication) (2 points)\n",
        "* 2.1.f) Calculate the eigenvalues of $A$ (7 points)\n",
        "* 2.1.g) Give one example of a property of the data that eigenvalues/eigenvectors represent (i.e., why is calculating the eigenvalues/eigenvectors useful)? (3 marks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRhMh6tJjvcc"
      },
      "source": [
        "# **3. Programming: introduction to Python, Colab and OpenCV (70 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4ecEgtjzOY"
      },
      "source": [
        "### **3.1 Basic image operations**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_yOTMF-S_e-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94a60f5-6166-4626-ef99-f533be7b5e82"
      },
      "source": [
        "import sys \n",
        "import os\n",
        "import cv2 # imports OpenCV\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt #imports matplotlib \n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline\n",
        "# You will NOT need to import any more libraries for ANY assignment. \n",
        "\n",
        "print('-'*40)\n",
        "print ('Python version: {}'.format(sys.version))\n",
        "print('OpenCV version: {}'.format(cv2.__version__))\n",
        "\n",
        "if not READ_THE_INSTRUCTIONS_FLAG:\n",
        "  raise Exception('Please go back and read the instructions.')\n",
        "else:\n",
        "  print('\\nThank you for reading the instructions.')\n",
        "print('-'*40)\n",
        "\n",
        "def pltImg(img, title=None, ori=\"horizontal\", colorb = True):  \n",
        "  plt.imshow(img)\n",
        "  if colorb:\n",
        "    plt.colorbar(orientation=ori)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  return plt\n",
        "\n",
        "\n",
        "# Here we simply download the needed images \n",
        "if os.path.isfile('./uvic_1.jpg'):\n",
        "  print('Image file already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/uvic_1.jpg\"\n",
        "\n",
        "if os.path.isfile('./gamma_original.jpg'):\n",
        "  print('Image file already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/gamma_original.jpg\"\n",
        "\n",
        "if os.path.isfile('./low_contrast.jpg'):\n",
        "  print('Low-contrast image file already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/low_contrast.jpg\"\n",
        "\n",
        "if os.path.isfile('./bw_target.jpg'):\n",
        "  print('B&W target image already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/bw_target.jpg\"\n",
        "\n",
        "if os.path.isfile('./color_reference.png'):\n",
        "  print('Color reference image already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/color_reference.jpg\""
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Python version: 3.8.10 (default, Nov 14 2022, 12:59:47) \n",
            "[GCC 9.4.0]\n",
            "OpenCV version: 4.6.0\n",
            "\n",
            "Thank you for reading the instructions.\n",
            "----------------------------------------\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "--2023-01-24 03:49:52--  https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/uvic_1.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 919735 (898K) [image/jpeg]\n",
            "uvic_1.jpg: No such file or directory\n",
            "\n",
            "Cannot write to ‘uvic_1.jpg’ (Success).\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "--2023-01-24 03:49:52--  https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/gamma_original.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81940 (80K) [image/jpeg]\n",
            "gamma_original.jpg: No such file or directory\n",
            "\n",
            "Cannot write to ‘gamma_original.jpg’ (Success).\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "--2023-01-24 03:49:52--  https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/low_contrast.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7579 (7.4K) [image/jpeg]\n",
            "low_contrast.jpg: No such file or directory\n",
            "\n",
            "Cannot write to ‘low_contrast.jpg’ (Success).\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "--2023-01-24 03:49:52--  https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/bw_target.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 196873 (192K) [image/jpeg]\n",
            "bw_target.jpg: No such file or directory\n",
            "\n",
            "Cannot write to ‘bw_target.jpg’ (Success).\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "--2023-01-24 03:49:53--  https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/color_reference.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4329119 (4.1M) [image/jpeg]\n",
            "color_reference.jpg: No such file or directory\n",
            "\n",
            "Cannot write to ‘color_reference.jpg’ (Success).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wICDEiOuI1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "738a8546-1a1a-40b1-eb17-1d0e81d5218b"
      },
      "source": [
        "# ~~~~~~~START TODO~~~~~~~~~\n",
        "# (2 points): use OpenCV (i.e., cv2) to read the \n",
        "# image at ./uvic_1.jpg print it's size and data type.\n",
        "# you may find cv2.imread helpful...\n",
        "path = r'./uvic_1.jpg'\n",
        "img = cv2.imread(path)\n",
        "size = img.shape[:2]\n",
        "dataType = img.dtype\n",
        "print(size)\n",
        "print(dataType)\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "# ~~~~~~~START TODO~~~~~~~~~ \n",
        "# (3 points): Use OpenCV to reduce the dimension of the image in 65%. \n",
        "# Print its dimensions and data type once again afterwards. \n",
        "# You may find cv2.resize helpful...\n",
        "width = int(img.shape[1]*0.65)\n",
        "height = int(img.shape[0]*0.65)\n",
        "newSize = (height, width)\n",
        "resizedImg = cv2.resize(img, newSize, interpolation=cv2.INTER_AREA)\n",
        "newDataType = resizedImg.dtype\n",
        "print(newSize)\n",
        "print(newDataType)\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-175-3c3bba749cd2>\", line 7, in <module>\n",
            "    size = img.shape[:2]\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 737, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 721, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.8/posixpath.py\", line 379, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dHyzfOaROGZ"
      },
      "source": [
        "**Plotting the image**: given that colab does not support OpenCV's \"imshow\", we will use matplotlib plotting functions (i.e., plt). [This](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.00-Introduction-To-Matplotlib.ipynb) is a great series of notebooks describing the use of matplotlib in Google Colab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JAX3dONRNRv"
      },
      "source": [
        "# ~~~~~~~START TODO~~~~~~~~~ \n",
        "# (5 points): Display, in the same plot, two images: the color input AND only\n",
        "# its GREEN channel. (tip: pay attention to the color space!)\n",
        "# Use the image you loaded and down-sized in the pervious section.\n",
        "# Not the color channel ordering for opencv when it opens an image.\n",
        "img = cv2.imread('./uvic_1.jpg')\n",
        "img_green = img.copy()\n",
        "# Set blue and red channels to 0\n",
        "img_green[:,:,0] = 0\n",
        "img_green[:,:,2] = 0\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "plt.figure(figsize = (15,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt = pltImg(img,title=\"Original color image\", ori='vertical')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt = pltImg(img_green,title = \"Green color channel\", ori='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87hMaXZDSAho"
      },
      "source": [
        "**Rescalling the image**: you will often work with image files in different ranges. Typical ranges include (but are not limited to) [0,1] and [0,255]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVLMLqSO039A"
      },
      "source": [
        "# ~~~~~~~START TODO~~~~~~~~~ \n",
        "# (5 points): rescale the image from the previous section \n",
        "# to the [0,1] range from the [0,255] range. \n",
        "# Print the new range of values of the image and \n",
        "# plot the new color image. \n",
        "# Ensure the type of our array is correct for the scaling to floats! \n",
        "img = cv2.imread('./uvic_1.jpg')\n",
        "rescaled = cv2.normalize(img, None, alpha=0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "print(rescaled)\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "plt.figure(figsize = (12,5))\n",
        "plt = pltImg(rescaled,title=\"Rescaled to [0,1]\", ori='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqlHHUUcKkla"
      },
      "source": [
        "from numpy.core.memmap import uint8\n",
        "def turnGray(img, threeD=True):\n",
        "  # ~~~~~~~START TODO~~~~~~~~~ \n",
        "  # (5 points):\n",
        "  # Create a grayscale version of the color image, without using OpenCV cvtColor.\n",
        "  # Note matplotlib will only plot floats in the range [0,1] and uint8 in the range [0,255]\n",
        "  # Source 1: https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert\n",
        "  # Source 2: https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n",
        "  converted = np.dot(img[...,:3], [299/1000, 587/1000, 114/1000])\n",
        "  return (np.rint(converted)).astype(np.uint8)\n",
        "  # ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "greyImg = turnGray(img)\n",
        "plt.figure(figsize = (12,12))\n",
        "plt = pltImg(greyImg, title='Greyscale image', colorb=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsc05nykJGVB"
      },
      "source": [
        "**Point operators**: these common operators will consider a single pixel intensity in the input image when calculating a given output intensity (conversely from neighborhood operators such as image filters), this is done with no spatial information conisdered.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWWEDOyxCvn2"
      },
      "source": [
        "# ~~~~~~~START TODO~~~~~~~~~ \n",
        "# (5 points): Create two modified versions of the rescaled image. \n",
        "# 1) Brighten the image by adding scalar 0.3 to all its pixel intensities;\n",
        "# 2) Darken the image by subtracting all pixel values by scalar 0.3. \n",
        "# Note 1: your input image should have pixel intensities inside range [0,1]. \n",
        "# Note 2: The pixel intensities of the modified image should be inside range [0,1] (i.e., clamp intensities if necessary).\n",
        "img = cv2.imread('./uvic_1.jpg')\n",
        "rescaled = cv2.normalize(img, None, alpha=0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "nonClampedBrighter = rescaled + 0.3\n",
        "brighter = np.clip(nonClampedBrighter, 0, 1.0)\n",
        "nonClampedDarker = rescaled - 0.3\n",
        "darker = np.clip(nonClampedDarker, 0, 1.0)\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "plt.figure(figsize = (14,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt = pltImg(brighter,title=\"Brighter image\", ori='vertical')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt = pltImg(darker,title = \"Darker image\", ori='vertical')\n",
        "plt.subplots_adjust(wspace=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T1Xr9mcJkVN"
      },
      "source": [
        "# ~~~~~~~START TODO~~~~~~~~~\n",
        "# (5 points): Perform gamma correction in the image located at \"./gamma_original.jpg\". \n",
        "# 1. Load the image from \"./gamma_original.jpg\"\n",
        "# 2. Perform gamma correction with gamma = 2.2.\n",
        "gamma = 2.2\n",
        "inverseGamma = 1 / gamma \n",
        "gamma_img = cv2.imread('./gamma_original.jpg')\n",
        "# Source: https://lindevs.com/apply-gamma-correction-to-an-image-using-opencv\n",
        "# Formula: O = (I / 255)^(1 / γ) * 255\n",
        "O = [((I / 255) ** inverseGamma) * 255 for I in range(256)]\n",
        "O = np.array(O, np.uint8)\n",
        "gamma_corrected = cv2.LUT(gamma_img, O)\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "plt.figure(figsize = (14,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt = pltImg(gamma_img,title=\"Original image\", colorb=False)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt = pltImg(gamma_corrected,title = \"Gamma corrected image\", colorb=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD4YuUu4wLyn"
      },
      "source": [
        "outDirectory = './output/'\n",
        "if not os.path.exists(outDirectory):\n",
        "    os.makedirs(outDirectory)\n",
        "    print(\"Created output folder.\")\n",
        "else:\n",
        "    print('Output folder already created.')\n",
        "\n",
        "# ~~~~~~~START TODO~~~~~~~~~\n",
        "# (5 points): Save all modified images (i.e., brigther, darker and greyscale) in your Colab working directory\n",
        "# with .jpg extensions using OpenCV's \"cv2.imwrite\". The images should be saved\n",
        "# in a folder named \"output\" (create this folder USING PYTHON if it does not yet exist).  \n",
        "# Tips: use \"cv2.normalize\". Be careful with the image ranges and types. The\n",
        "# saved images should preserve the \"brighter\", \"darker\" and \"grey\" effects. \n",
        "# Rescaling from [0, 1] to [0, 255], rounding to the nearest integer and clamping values to be integers between [0, 255]\n",
        "brighter = cv2.normalize(brighter, None, alpha=0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "#brighter = (np.rint(brighter)).astype(np.uint8)\n",
        "#brighter = np.clip(brighter, 0, 255)\n",
        "cv2.imwrite(os.path.join('./output/', 'brighter.jpg'), brighter)\n",
        "\n",
        "darker = cv2.normalize(darker, None, alpha=0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "#darker = (np.rint(darker)).astype(np.uint8)\n",
        "#darker = np.clip(darker, 0, 255)\n",
        "cv2.imwrite(os.path.join('./output/', 'darker.jpg'), darker)\n",
        "\n",
        "cv2.imwrite(os.path.join('./output/', 'greyscale.jpg'), greyImg)\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHfrcvQMQngJ"
      },
      "source": [
        "### **3.2 Histogram calculation and matching** (50 points)\n",
        "\n",
        "As discussed in class, histogram matching approximates a given pixel intensity frequency distribution (i.e., histogram) to a second, reference one. In this part of the assignment you are asked to create a function to implement such an algorithm. See slides from the Point Operators and Histogram discussion for details on the Histogram matching algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2brFjpeDQdtW"
      },
      "source": [
        "hist = None\n",
        "cumulative_hist = None\n",
        "def myHistogram(I, cumulative=True):\n",
        "    H = None\n",
        "    # ~~~~~~~START TODO~~~~~~~~~\n",
        "    # (13 points): Implement a function that calculates the histogram and the cumulative histogram of a given image MANUALLY.\n",
        "    # You CANNOT use any automated functions for histogram calculation (e.g., matplotlib.plt.hist, np.histogram, cv2.createCLAHE,\n",
        "    # cv2.calcHist). Use the function template provided by filling it with your code. \n",
        "\n",
        "    # ~~~~~~~~END TODO~~~~~~~~~~\n",
        "    return H # H is either the histogram or cumulative histogram of I (depending on the value of\n",
        "\n",
        "\n",
        "# ~~~~~~~START TODO~~~~~~~~~\n",
        "# (2 points): Read the image at \"./low_contrast.jpg\" with OpenCV as a single channel, \n",
        "# greyscale image. Calculate its regular and cumulative histograms using your \"myHistogram\" function,\n",
        "# and display both of them in the same matplotlib plot. \n",
        "\n",
        "\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "\n",
        "# plots the histograms\n",
        "plt.figure(figsize = (12,7))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.bar(np.arange(256),hist)\n",
        "plt.title('Histogram')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(np.arange(256),cumulative_hist)\n",
        "plt.title('Cumulative histogram')\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft_4Ny3jGkD7"
      },
      "source": [
        "\n",
        "\n",
        "def match_histogram(I, Href, nref, debug=False):\n",
        "    # ~~~~~~~START TODO~~~~~~~~~\n",
        "    # TO-DO (10 points): Create a \"match_histogram\" function to implement the histogram matching algorithm. This function \n",
        "    # receives an image, a reference cumulative histogram (previously calculated) and a reference number (you\n",
        "    # can use the maximum value of the reference cumulative histogram as a default for this parameter). Its output is a \n",
        "    # transformation function F(x) that will map an input pixel intensity to an output pixel intensity. For example, \n",
        "    # if F[11]=17, an input pixel with intensity 11 should be replaced by one of intensity 17. See the details of the\n",
        "    # algorithm in the Histogram lecture, available on BrightSpace. Use the function skeleton provided. (5 points)\n",
        "\n",
        "    # ~~~~~~~~END TODO~~~~~~~~~~\n",
        "    return F\n",
        "\n",
        "\n",
        "# ~~~~~~~START TODO~~~~~~~~~\n",
        "# TO-DO (1 points): Create a numpy array called Href with 256 positions populated with values 0,1,2,...,255.\n",
        "\n",
        "# TO-DO (1 points): Calculate the cumulative histogram of Href using your myHistogram function. This is \n",
        "# going to represent your reference cumulative histogram.\n",
        "\n",
        "# TO-DO (1 points): Use your \"match_histogram\" function where I is the low contrast image and Href is the \n",
        "# cumulative histogram you just calculated. You will obtain transformation function F. \n",
        "\n",
        "# TO-DO (2 points): Apply F (the transformation function you just calculated) to transform\n",
        "# the pixel intensities from the original image to that of the histogram-matched\n",
        "# one. You should obtain the histogram-matched image as a result of this operation.\n",
        "\n",
        "# ~~~~~~~~END TODO~~~~~~~~~~\n",
        "\n",
        "out_hist = myHistogram(histogram_matched,cumulative=False) # calculates the histogram of the output image\n",
        "final_plot = np.repeat(histogram_matched[:, :, np.newaxis], 3, axis=2)  # turns into 3-channel image for plotting purposes\n",
        "lowc_plot = np.repeat(lowc[:, :, np.newaxis], 3, axis=2)  # turns into 3-channel image for plotting purposes\n",
        "\n",
        "plt.figure(figsize = (9,9))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.bar(np.arange(256),hist)\n",
        "plt.title('Original histogram')\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(lowc_plot)\n",
        "plt.title('Original image')\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.bar(np.arange(256),out_hist)\n",
        "plt.title('Output image histogram')\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(final_plot)\n",
        "plt.title('Output image')\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
        "plt.show()\n",
        "\n",
        "# [Debug only]: the two cumulative histograms, although representing images with \n",
        "# different numbers of pixels (>35,000 for the input, 256 for the reference),\n",
        "# should present a similar shape after the matching\n",
        "\n",
        "out_cumulative = myHistogram(histogram_matched,cumulative=True)\n",
        "plt.figure(figsize = (9,9))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Matched cumulative histogram')\n",
        "plt.bar(np.arange(256),out_cumulative)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Reference cumulative histogram')\n",
        "plt.bar(np.arange(256),Href)\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ey3e0W5G0V"
      },
      "source": [
        " \n",
        "\n",
        "def matchRGB(target, reference):\n",
        "    # ~~~~~~~START TODO~~~~~~~~~\n",
        "    # TO-DO (10 points): Adapt the histogram matching procedure to 3-channel images \n",
        "    # (i.e., a single histogram matching process done three times). \n",
        "    # Download and read the images at the \"color_reference_add\" and \n",
        "    # \"bw_target_add\" addresses. Use the color image to calculate \n",
        "    # the refence cumulative histograms, and the B&W image as a target of the \n",
        "    # histogram matching process. Note that both images are 3-channel.\n",
        "\n",
        "    # ~~~~~~~~END TODO~~~~~~~~~~\n",
        "    return targetFinal\n",
        "\n",
        "colorRef = cv2.imread('./color_reference.jpg')\n",
        "bwImg = cv2.imread('./bw_target.jpg')\n",
        "h, w = colorRef.shape[:2]\n",
        "final = matchRGB(bwImg,colorRef)\n",
        "\n",
        "plt.figure(figsize = (12,9))\n",
        "plt.subplot(3,1,1)\n",
        "plt = pltImg(cv2.cvtColor(bwImg,cv2.COLOR_BGR2RGB),title=\"Input 1-Channel Image\",colorb=False)\n",
        "plt.subplot(3,1,2)\n",
        "plt = pltImg(cv2.cvtColor(colorRef,cv2.COLOR_BGR2RGB),title=\"Color Reference\",colorb=False)\n",
        "plt.subplot(3,1,3)\n",
        "plt = pltImg(cv2.cvtColor(final,cv2.COLOR_BGR2RGB),title=\"OutputImage\",colorb=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENSjUV3ATDm9"
      },
      "source": [
        "**End of the assignment!**"
      ]
    }
  ]
}